{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgnQTvE7oTSX",
        "outputId": "f62c23d1-3990-4b91-9e12-b529475fbff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (50, 7830, 3)\n",
            "Target shape: (50, 7830, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load input (features) and output (targets)\n",
        "data = np.load(\"X.npy\")  # Shape: (samples, time_steps, features)\n",
        "target = np.load(\"ynpy.npy\")  # Shape: (samples, output_dim)\n",
        "\n",
        "print(f\"Data shape: {data.shape}\")  # Should be (samples, 5, 3)\n",
        "print(f\"Target shape: {target.shape}\")  # Should be (samples, 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "kJk1OVJmoT-v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_time_windows(imu_data, gps_data, input_window=5):\n",
        "    \"\"\"\n",
        "    Convert IMU and GPS time-series data into overlapping sequences for LSTM training.\n",
        "\n",
        "    Args:\n",
        "    - imu_data (np.array): IMU data of shape (runs, timesteps, imu_features)\n",
        "    - gps_data (np.array): GPS data of shape (runs, timesteps, gps_features)\n",
        "    - input_window (int): Number of time steps per sequence\n",
        "\n",
        "    Returns:\n",
        "    - X: Input sequences of shape (samples, input_window, imu_features + gps_features)\n",
        "    - y: Corresponding target GPS values of shape (samples, gps_features)\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    num_runs, timesteps, imu_features = imu_data.shape\n",
        "    gps_features = gps_data.shape[2]\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        for i in range(timesteps - input_window):\n",
        "            # Extract past IMU and GPS time window\n",
        "            imu_seq = imu_data[run, i:i+input_window, :]\n",
        "            gps_seq = gps_data[run, i:i+input_window, :]\n",
        "\n",
        "            # Concatenate IMU and GPS for input\n",
        "            input_seq = np.concatenate([imu_seq, gps_seq], axis=-1)\n",
        "            X.append(input_seq)\n",
        "\n",
        "            # Extract target (next time step GPS values)\n",
        "            y.append(gps_data[run, i+input_window, :])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load IMU and GPS data\n",
        "imu_data = np.load(\"X.npy\")  # Shape: (runs, timesteps, imu_features)\n",
        "gps_data = np.load(\"ynpy.npy\")  # Shape: (runs, timesteps, gps_features)\n",
        "\n",
        "# Convert data into time-windowed sequences\n",
        "X, y = create_time_windows(imu_data, gps_data, input_window=5)\n",
        "\n",
        "print(f\"Processed Data Shape: {X.shape}\")  # (samples, 5, imu_features + gps_features)\n",
        "print(f\"Processed Labels Shape: {y.shape}\")  # (samples, gps_features)\n",
        "\n",
        "# Save processed data\n",
        "np.save(\"X_processed.npy\", X)\n",
        "np.save(\"y_processed.npy\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhSTWzNuoVqi",
        "outputId": "b7f40603-64a6-4626-d726-9d3154763dab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Data Shape: (391250, 5, 6)\n",
            "Processed Labels Shape: (391250, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Initialize scalers\n",
        "scaler = MinMaxScaler()  # Use MinMaxScaler for GPS coordinates\n",
        "imu_scaler = StandardScaler()  # Use StandardScaler for IMU data if necessary\n",
        "\n",
        "# Flatten the data to fit the scaler\n",
        "X_flattened = X.reshape(-1, X.shape[-1])\n",
        "y_flattened = y.reshape(-1, y.shape[-1])\n",
        "\n",
        "# Apply normalization\n",
        "X_scaled = scaler.fit_transform(X_flattened)\n",
        "y_scaled = scaler.fit_transform(y_flattened)\n",
        "\n",
        "# Reshape back to original dimensions\n",
        "X_scaled = X_scaled.reshape(X.shape)\n",
        "y_scaled = y_scaled.reshape(y.shape)"
      ],
      "metadata": {
        "id": "Q1cTTpHuoY8y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "# Print shapes\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQT1c5WDofd8",
        "outputId": "0aa9f0e9-d7c8-47e8-9696-d48578e779c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (313000, 5, 6), X_test shape: (78250, 5, 6)\n",
            "y_train shape: (313000, 3), y_test shape: (78250, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dot, Activation, Concatenate, Flatten\n",
        "\n",
        "# Define input shapes\n",
        "time_steps = X.shape[1]  # Sequence length (past 5 seconds of data)\n",
        "num_features = X.shape[2]  # Number of input features per time step (IMU + GPS)\n",
        "output_dim = y.shape[1]\n",
        "# Define inputs\n",
        "inputs = Input(shape=(time_steps, num_features), name=\"Input_Features\")\n",
        "\n",
        "# Encoder (LSTM)\n",
        "encoder_lstm = LSTM(64, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(inputs)\n",
        "\n",
        "# Attention Mechanism (Local Attention)\n",
        "# Calculate attention scores (alignment scores)\n",
        "attention_scores = Dense(1, activation='tanh', name=\"Attention_Scores\")(encoder_outputs)\n",
        "\n",
        "#Normalize scores to obtain attention weights\n",
        "attention_weights = Activation('softmax', name=\"Attention_Weights\")(attention_scores)\n",
        "\n",
        "#Compute the context vector as the weighted sum of encoder outputs\n",
        "context_vector = Dot(axes=1, name=\"Context_Vector\")([attention_weights, encoder_outputs])\n",
        "\n",
        "# Decoder (Fully Connected Layer)\n",
        "decoder_dense = Dense(64, activation='relu', name=\"Decoder_Dense\")(context_vector)\n",
        "\n",
        "# Output Layer (Latitude, Longitude, Altitude)\n",
        "output_layer = Dense(3, activation='linear', name=\"Trajectory_Output\")(decoder_dense)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output_layer, name=\"Trajectory_Prediction_Model\")\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "2hE1_CfsohQm",
        "outputId": "9286af5e-f100-44d2-9f61-97969014da2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Trajectory_Prediction_Model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Trajectory_Prediction_Model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_Features            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Encoder_LSTM (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, │         \u001b[38;5;34m18,176\u001b[0m │ Input_Features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                           │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Attention_Scores (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │             \u001b[38;5;34m65\u001b[0m │ Encoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Attention_Weights         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ Attention_Scores[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Context_Vector (\u001b[38;5;33mDot\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ Attention_Weights[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │                        │                │ Encoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Decoder_Dense (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m4,160\u001b[0m │ Context_Vector[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Trajectory_Output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │            \u001b[38;5;34m195\u001b[0m │ Decoder_Dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_Features            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Encoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,176</span> │ Input_Features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Attention_Scores (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Attention_Weights         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Attention_Scores[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Context_Vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Attention_Weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │                        │                │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Decoder_Dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ Context_Vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Trajectory_Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ Decoder_Dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,596\u001b[0m (88.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,596</span> (88.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,596\u001b[0m (88.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,596</span> (88.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Early stopping to monitor validation loss and stop if no improvement\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=150,  # Maximum epochs\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,  # 20% of training data for validation\n",
        "    callbacks=[early_stopping]  # Use early stopping\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('trajectory_prediction_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMjlIg4ZpGP-",
        "outputId": "3355b1d5-7163-459c-da91-93357e4edd65"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m3912/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0880 - mae: 0.2444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 5, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - loss: 0.0880 - mae: 0.2444 - val_loss: 0.0878 - val_mae: 0.2491\n",
            "Epoch 2/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2440 - val_loss: 0.0875 - val_mae: 0.2436\n",
            "Epoch 3/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 10ms/step - loss: 0.0876 - mae: 0.2437 - val_loss: 0.0874 - val_mae: 0.2420\n",
            "Epoch 4/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8ms/step - loss: 0.0876 - mae: 0.2440 - val_loss: 0.0874 - val_mae: 0.2437\n",
            "Epoch 5/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - loss: 0.0876 - mae: 0.2438 - val_loss: 0.0874 - val_mae: 0.2421\n",
            "Epoch 6/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2442 - val_loss: 0.0874 - val_mae: 0.2450\n",
            "Epoch 7/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2440 - val_loss: 0.0873 - val_mae: 0.2448\n",
            "Epoch 8/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2443 - val_loss: 0.0874 - val_mae: 0.2414\n",
            "Epoch 9/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0876 - mae: 0.2439 - val_loss: 0.0874 - val_mae: 0.2412\n",
            "Epoch 10/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2439 - val_loss: 0.0874 - val_mae: 0.2459\n",
            "Epoch 11/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - loss: 0.0875 - mae: 0.2436 - val_loss: 0.0875 - val_mae: 0.2467\n",
            "Epoch 12/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - loss: 0.0876 - mae: 0.2440 - val_loss: 0.0874 - val_mae: 0.2418\n",
            "Epoch 13/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 9ms/step - loss: 0.0875 - mae: 0.2438 - val_loss: 0.0874 - val_mae: 0.2442\n",
            "Epoch 14/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2444 - val_loss: 0.0873 - val_mae: 0.2430\n",
            "Epoch 15/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - loss: 0.0875 - mae: 0.2437 - val_loss: 0.0873 - val_mae: 0.2441\n",
            "Epoch 16/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - loss: 0.0876 - mae: 0.2439 - val_loss: 0.0874 - val_mae: 0.2428\n",
            "Epoch 17/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - loss: 0.0874 - mae: 0.2434 - val_loss: 0.0873 - val_mae: 0.2436\n",
            "Epoch 18/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - loss: 0.0878 - mae: 0.2445 - val_loss: 0.0874 - val_mae: 0.2438\n",
            "Epoch 19/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 9ms/step - loss: 0.0875 - mae: 0.2436 - val_loss: 0.0873 - val_mae: 0.2438\n",
            "Epoch 20/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 9ms/step - loss: 0.0875 - mae: 0.2439 - val_loss: 0.0873 - val_mae: 0.2426\n",
            "Epoch 21/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9ms/step - loss: 0.0874 - mae: 0.2436 - val_loss: 0.0873 - val_mae: 0.2430\n",
            "Epoch 22/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0876 - mae: 0.2438 - val_loss: 0.0873 - val_mae: 0.2441\n",
            "Epoch 23/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2442 - val_loss: 0.0873 - val_mae: 0.2429\n",
            "Epoch 24/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - loss: 0.0876 - mae: 0.2440 - val_loss: 0.0874 - val_mae: 0.2447\n",
            "Epoch 25/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9ms/step - loss: 0.0874 - mae: 0.2436 - val_loss: 0.0873 - val_mae: 0.2419\n",
            "Epoch 26/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0875 - mae: 0.2437 - val_loss: 0.0873 - val_mae: 0.2436\n",
            "Epoch 27/150\n",
            "\u001b[1m3913/3913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - loss: 0.0877 - mae: 0.2443 - val_loss: 0.0874 - val_mae: 0.2433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print(f\"Test Loss (MSE): {test_loss}\")\n",
        "print(f\"Test Mean Absolute Error (MAE): {test_mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3D4C1k-pLJL",
        "outputId": "ee309844-5590-4239-f48e-560e6c56f36e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2446/2446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0871 - mae: 0.2432\n",
            "Test Loss (MSE): 0.08756671845912933\n",
            "Test Mean Absolute Error (MAE): 0.24403154850006104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.squeeze(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3I_YATVuZwq",
        "outputId": "30f6e6ed-b948-46bc-ce5e-90478edbcd6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m  28/2446\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2ms/step    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 5, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2446/2446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Compute MAE, RMSE, and R^2 score for Latitude, Longitude, and Altitude\n",
        "mae = mean_absolute_error(y_test, y_pred, multioutput='raw_values')\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
        "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
        "\n",
        "# Print results\n",
        "print(f\"Mean Absolute Error (MAE): Latitude={mae[0]:.6f}, Longitude={mae[1]:.6f}, Altitude={mae[2]:.6f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): Latitude={rmse[0]:.6f}, Longitude={rmse[1]:.6f}, Altitude={rmse[2]:.6f}\")\n",
        "print(f\"R² Score: Latitude={r2[0]:.6f}, Longitude={r2[1]:.6f}, Altitude={r2[2]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gMYp5-GtyAu",
        "outputId": "f5453a37-f393-4499-9431-ec110392d530"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): Latitude=0.267549, Longitude=0.248628, Altitude=0.207124\n",
            "Root Mean Squared Error (RMSE): Latitude=0.300495, Longitude=0.290920, Altitude=0.285379\n",
            "R² Score: Latitude=0.024613, Longitude=0.021223, Altitude=0.027897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5joYMNxv8Cs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}